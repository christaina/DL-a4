max_grad_norm: 5
seq_length: 20
batch_size: 20
lr: 0.05
max_max_epoch: 15
rnn_size: 200
init_weight: 0.1
decay: 1.2
dropout: 0.5
layers: 2
vocab_size: 10000
max_epoch: 4
