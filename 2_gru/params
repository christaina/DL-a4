max_grad_norm: 5
seq_length: 30
batch_size: 20
lr: 0.1
max_max_epoch: 15
rnn_size: 200
init_weight: 0.1
decay: 2
dropout: 0
layers: 2
vocab_size: 10000
max_epoch: 4
